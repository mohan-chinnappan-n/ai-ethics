# Guidelines for the ethical use of AI

Ethical use of AI is a critical consideration in the development and deployment of artificial intelligence technologies. AI has the potential to bring about significant positive impacts on society, but it also raises important **ethical concerns and challenges**. Here are some key principles and guidelines for the ethical use of AI:

1. **Fairness and Bias Mitigation**:
   - Ensure that AI systems are designed and trained to be fair and unbiased, treating all individuals and groups fairly regardless of their demographic characteristics.
   - Regularly audit AI systems for bias and discrimination and take corrective measures when bias is identified.
   - Socially beneficial is something we can be proud of.
   
2. **Transparency and Explainability**:
   - Make AI systems transparent and explainable so that users and stakeholders can understand how decisions are made.
   - Provide clear explanations for AI-driven decisions, especially in critical applications like healthcare, finance, and criminal justice.
   - **Provide infomation about source on which the generated answer is based on**
      - What data is the AI system using?
      - How is the AI system processing the data?
      - What features are most important to the AI system in making decisions?
      - What are the limitations of the AI system?

3. **Privacy and Data Protection**:
   - Respect individuals' privacy by collecting and processing data in a manner that complies with privacy laws and regulations.
   - Implement robust data security measures to **protect sensitive information from unauthorized access or breaches**.
   - ![privacy](img/privacy.jpeg)

4. **Accountability**:
   - Establish clear lines of accountability for AI systems and their outcomes including providing citations and credits to the folks who created the original content.
   - Hold developers, organizations, and users **accountable** for the ethical use of AI technologies.

5. **Inclusivity and Accessibility**:
   - Ensure that AI technologies are **accessible to all individuals, including those with disabilities**.
   - Consider the needs of diverse user groups when designing and deploying AI systems.
      - Being mindful of LLM output and avoiding stereotypes and assumptions
      - Making sure that this technology is accessible to everyone
      - Should create a culture of respect and belonging
   - ![inclusive](img/inclusive.jpeg)

6. **Safety and Risk Mitigation**:
   - Prioritize the safety of AI systems, especially in applications like autonomous vehicles and medical devices.
   - Implement fail-safe mechanisms and rigorous testing to minimize risks associated with AI.
      - Conducting thorough risk assessments
      - Implementing safety measures, such as monitoring and oversight systems
      - Testing AI systems thoroughly before deploying them
      - Having a plan in place to respond to incidents
   ![Safety](img/saftey-1.jpeg)


7. **Human Oversight**:
   - Maintain **human oversight and control over AI systems**, particularly in high-stakes decision-making processes.
   - **Avoid fully autonomous AI systems in contexts where human judgment is essential**.
      - Monitoring and auditing AI systems to ensure that they are operating as intended
      - Intervening to override AI systems if necessary
   ![Human Oversight](img/human-oversight-1.jpeg)


8. **Ethical AI Education**:
   - Promote education and awareness about AI ethics among developers, data scientists, policymakers, and the general public.
   - Encourage responsible AI research and development practices. This should cover:
      - The principles of AI ethics
      - The potential benefits and risks of AI
      - How to design and build AI systems that are fair, equitable, and transparent
      - How to mitigate the risks associated with AI systems
      - How to use AI systems in a responsible and ethical manner

9. **Societal Impact Assessment**:
   - Conduct impact assessments to understand how AI technologies may affect society, employment, and various industries.
   - Take measures to address potential negative consequences.
      - The potential benefits of the AI system
      - The potential risks of the AI system
      - The potential impacts on different groups of people
      - The potential impacts on different aspects of society
   ![Social Impact](img/socialImpact.jpeg)

10. **Legal and Regulatory Compliance**:
    - Comply with relevant laws and regulations governing AI in specific domains and regions.
    - Advocate for ethical AI policies and regulations where necessary covering:
      - Data privacy and security
      - Transparency and explainability
      - Fairness and equity
      - Safety and risk management
      - Human oversight
## AI companies Ethics 

- [Google](./google.md)
- [Meta](./meta.md)
- [Microsoft](./microsoft-ai.pdf)
- [Salesforce](./sfdc.md)

## Resources
- [Open Ethics Initiative](https://openethics.ai/)
- [Fathers of AI](./fathers.md)

- [Google: Objectives for AI applications](https://ai.google/responsibility/principles/)
- [Metaâ€™s five pillars of responsible AI that inform our work](https://ai.meta.com/responsible-ai/)

- [Salesforce Trusted AI](https://www.salesforceairesearch.com/trusted-ai)
- [Ethical Use Policy](https://www.salesforce.com/company/intentional-innovation/ethical-use-policy/)



